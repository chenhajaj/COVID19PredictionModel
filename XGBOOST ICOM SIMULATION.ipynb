{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICoM Simulation for XGBOOST notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this running the simulation please make sure you have:\n",
    "\n",
    "1)list of csv with countries\n",
    "2)csv contating geographic data\n",
    "\n",
    "In this notebook we will simulate the ICoM Movment by predicting the growth in each country and cacluate the predicted cases in each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "pd.options.mode.chained_assignment = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "\n",
    "def train(df):\n",
    "    x=df.iloc[10:32,17:-1]\n",
    "    y=df.iloc[10:32,-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,random_state=0)\n",
    "\n",
    "\n",
    "    regressor = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1,  subsample=0.5,\n",
    "                           colsample_bytree=0.1, max_depth=3,random_state=0,objective=\"reg:squarederror\",\n",
    "                        min_child_weight=1\n",
    "                          )\n",
    "    \n",
    "    regressor.fit(x_train,y_train)\n",
    "    feature_importances = pd.DataFrame(regressor.feature_importances_,\n",
    "                                   index = x_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "\n",
    "    #print(feature_importances)\n",
    "    return regressor,feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function on t+1 of weekly growth in each country\n",
    "\n",
    "def predict(df,i,regressor):\n",
    "    \n",
    "    x=df.iloc[:33+i,17:-1]\n",
    "    y=df.iloc[:33+i,-1]\n",
    "    predictions=regressor.predict(x)\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'Actual_rf': y, 'Predicted_rf': predictions})\n",
    "    df.plot(kind='bar',figsize=(10,10))\n",
    "    plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "    plt.title(\"Random forest\",fontsize=16)\n",
    "    plt.xlabel('Date ',fontsize=16)\n",
    "    plt.ylabel('Growth',fontsize=16)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    #print (\"Xgboost Model Score: %s\" % (regressor.score(x, y)))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ICom based on the caculated confirmed cases based on the prediction of the weekly growth\n",
    "\n",
    "def ICoM(gdict, tseries, c_r, states):\n",
    "\n",
    "    icom = []\n",
    "    numerator = []\n",
    "    denominator = []\n",
    "    for state in states:\n",
    "        coordinates = np.array([gdict[state][0], gdict[state][1]])\n",
    "        numerator.append(c_r[state] * coordinates)\n",
    "        denominator.append(c_r[state])\n",
    "    numerator = np.sum(np.array(numerator), axis=0)\n",
    "    denominator = sum(denominator)\n",
    "    if denominator == 0:\n",
    "        icom.append(np.array([0, 0]))\n",
    "    else:\n",
    "        icom.append(numerator * (1/denominator))\n",
    "    icom = np.array(icom)\n",
    "    icom = pd.DataFrame({'date': tseries, 'lat': icom[:, 0], 'long': icom[:, 1]})\n",
    "    dist=distFromCenter(icom,gdict,states)\n",
    "    return icom , dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create distance from the center based on the ICoM that was created\n",
    "def distFromCenter(centers, gdict, states):\n",
    "\n",
    "    weekly_dist = {}\n",
    "    for index in centers.index:\n",
    "        center = np.array(centers['lat'][index], centers['long'][index])\n",
    "        for key in gdict:\n",
    "            point = np.array(gdict[key])\n",
    "            distance = np.linalg.norm(center - point)\n",
    "            if key in states:\n",
    "                if key not in weekly_dist.keys():\n",
    "                    weekly_dist[key] = [distance]\n",
    "                else:\n",
    "                    weekly_dist[key].append(distance)\n",
    "    return weekly_dist"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "geo=pd.read_csv(\"geo.csv\")\n",
    "geo.rename(columns = {\"Unnamed: 0\":\"state\",\"0\":\"lat\",\"1\":\"long\"},inplace=True)\n",
    "geo=geo.set_index('state').T.to_dict('list')\n",
    "df_icom=pd.DataFrame()\n",
    "last_val={}\n",
    "df=pd.read_csv(\"France.csv\")\n",
    "t_s=df[\"date\"][32:37]\n",
    "\n",
    "state_dict={}\n",
    "predictions={}\n",
    "state_list=[\n",
    "\n",
    "\n",
    "'Germany', 'Italy', 'Spain', 'Belgium', 'Switzerland', 'Austria',\n",
    "           'France',\n",
    "           \n",
    "          'Finland', 'Greece', \n",
    "            'Netherlands'\n",
    "\n",
    "\n",
    "          ]\n",
    "\n",
    "\n",
    "\n",
    "for state in state_list:\n",
    "    df=pd.read_csv(state+\".csv\")\n",
    "    df.rename(columns={'Road passenger transport by buses and coaches[Milions]':\"Road\",'Rail passenger transport[Milions]':\"Rail\",\n",
    "            \"flights transportation[year]\":\"Flight\",'Population Density[ppl/km^2]':\"Population Density\",\"social spending[% of GPD]\":\"social spending\",\n",
    "             'GDP per capita[$]':\"GDP\" },inplace=True)\n",
    "    if state not in state_dict.keys():\n",
    "        state_dict[state]=df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read geographic data\n",
    "geo=pd.read_csv(\"geo.csv\")\n",
    "geo.rename(columns = {\"Unnamed: 0\":\"state\",\"0\":\"lat\",\"1\":\"long\"},inplace=True)\n",
    "geo=geo.set_index('state').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dataframe to save the ICOM prediction\n",
    "df_icom=pd.DataFrame()\n",
    "last_val={}\n",
    "df=pd.read_csv(\"France.csv\")\n",
    "t_s=df[\"date\"][32:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a diconery of dataframes where key is the country name\n",
    "state_dict={}\n",
    "predictions={}\n",
    "state_list=['Germany', 'Italy', 'Spain', 'Belgium', 'Switzerland', 'Austria',\n",
    "'France','Finland', 'Greece', 'Netherlands']\n",
    "\n",
    "\n",
    "\n",
    "for state in state_list:\n",
    "    df=pd.read_csv(state+\".csv\")\n",
    "    if state not in state_dict.keys():\n",
    "        state_dict[state]=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the original\n",
    "original_data={}\n",
    "for state in state_list:\n",
    "    if state not in original_data.keys():\n",
    "        original_data[state]=state_dict[state].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "for state in state_list:\n",
    "    original_data[state]=original_data[state].rename(columns={\"WeeklyConfirmed\":\"WeeklyConfirmed_real\",\"WeeklyGrowth\":\"WeeklyGrowth_real\",\n",
    "                                           \"Weeklydistance\":\"Weeklydistance_real\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of trained models and extrect feature imporance for each model\n",
    "train_dict={}\n",
    "feature_df = pd.DataFrame()\n",
    "for state in state_list:\n",
    "    if state not in train_dict.keys():\n",
    "        train_dict[state],data=train(state_dict[state])\n",
    "        \n",
    "        \n",
    "        feature_df=feature_df.append(data)\n",
    "        #print(state)\n",
    "    \n",
    "        \n",
    "        \n",
    "feature_df.to_csv(\"feature importance XGBOOST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date        lat      long\n",
      "0     0  45.027635  4.142377\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     1  44.940221  3.896906\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     2  44.850458  3.655784\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     3  44.760259  3.419197\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     4  44.668229  3.189073\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create prediction for the Weekly Growth for every trained model \n",
    "Caculate the Weekly Confiremd Cases based on the predicted Growth for t+1\n",
    "Caculate New ICoM Based on the predicted Confirmed Cases\n",
    "Caculate distance from Center of ICoM for each country\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(t_s)):\n",
    "\n",
    "   \n",
    "    for state in state_list:\n",
    "        \n",
    "        if state not in predictions.keys():\n",
    "            \n",
    "            predictions[state]=predict(state_dict[state],i,train_dict[state])\n",
    "            \n",
    "            \n",
    "        state_dict[state][\"WeeklyGrowth\"][32+i]=predictions[state][32+i]\n",
    "        state_dict[state][\"WeeklyConfirmed\"][32+i]=state_dict[state][\"WeeklyGrowth\"][32+i]*state_dict[state][\"WeeklyConfirmed\"][31+i]\n",
    "        \n",
    "        if state not in last_val.keys():\n",
    "            last_val[state]= state_dict[state][\"WeeklyConfirmed\"][32+i]\n",
    "            \n",
    "\n",
    "    \n",
    "    icom ,dist =ICoM(geo,i,last_val,state_list)\n",
    "    df_icom=df_icom.append(icom)\n",
    "    for state in state_list:\n",
    "        \n",
    "        state_dict[state][\"Weeklydistance\"][32+i]=dist[state][0]\n",
    "        \n",
    "    \n",
    "    last_val.clear()\n",
    "    predictions.clear()\n",
    "    print(icom)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write all the Data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "\n",
    "workbook = xlsxwriter.Workbook('predictions_growth_xgboost.xlsx')\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = load_workbook('predictions_growth_xgboost.xlsx')\n",
    "writer = pd.ExcelWriter('predictions_growth_xgboost.xlsx', engine = 'openpyxl')\n",
    "writer.book = book\n",
    "for state in state_list:\n",
    "    \n",
    "\n",
    "    \n",
    "    df[\"date\"].to_excel(writer, sheet_name=state,index=False)\n",
    "    state_dict[state][\"WeeklyConfirmed\"].to_excel(writer, sheet_name=state,index=False,startcol=1)\n",
    "    state_dict[state][\"WeeklyGrowth\"].to_excel(writer, sheet_name=state,index=False,startcol=2)\n",
    "    state_dict[state][\"Weeklydistance\"].to_excel(writer, sheet_name=state,index=False,startcol=3)\n",
    "    original_data[state][\"WeeklyConfirmed_real\"].to_excel(writer, sheet_name=state,startcol=4,index=False)\n",
    "    original_data[state][\"WeeklyGrowth_real\"].to_excel(writer, sheet_name=state,startcol=5,index=False)\n",
    "    original_data[state][\"Weeklydistance_real\"].to_excel(writer, sheet_name=state,startcol=6,index=False)\n",
    "    writer.save()\n",
    "writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = load_workbook('predictions_growth_xgboost.xlsx')\n",
    "writer = pd.ExcelWriter('predictions_growth_xgboost.xlsx', engine = 'openpyxl')\n",
    "writer.book = book\n",
    "df_icom.to_excel(writer,sheet_name=\"ICOM\")\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
