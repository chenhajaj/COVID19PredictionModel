{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICoM Simulation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this running the simulation please make sure you have:\n",
    "\n",
    "1)list of csv with countries\n",
    "2)csv contating geographic data\n",
    "\n",
    "In this notebook we will simulate the ICoM Movment by predicting the growth in each country and cacluate the predicted cases in each country.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#model for testings\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function\n",
    "\n",
    "def train(df):\n",
    "    x=df.iloc[10:32,17:-1]\n",
    "    y=df.iloc[10:32,-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,random_state=0)\n",
    "    \n",
    "    regressor = RandomForestRegressor(n_estimators = 50,max_depth=10,random_state=0,criterion=\"mse\",min_samples_leaf=1,\n",
    "                                 min_samples_split=2,bootstrap=True,max_features= 'auto')\n",
    "    \n",
    "    \n",
    "    #regressor = LinearRegression()\n",
    "    #regressor = Ridge(alpha=1)\n",
    "    #regressor = Ridge(alpha=50)\n",
    "    #regressor = Lasso(alpha=1)\n",
    "    #regressor = Lasso(alpha=50)\n",
    "    #regressor = SVR(kernel = 'rbf')\n",
    "    #regressor = MLPRegressor()\n",
    "    \n",
    "    #fit the model\n",
    "    regressor.fit(x_train, y_train)\n",
    "\n",
    "    \n",
    "    # summarize feature importance\n",
    "    feature_importances = pd.DataFrame(regressor.feature_importances_,\n",
    "                                   index = x_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "    feature_importances.reset_index(inplace=True)\n",
    "        \n",
    "        \n",
    "    #print(feature_importances)\n",
    "    #print(\"Random forest Model Score: %s\" % (regressor.score(x_test, y_test)))\n",
    "    \n",
    "    return regressor,feature_importances\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction function on t+1 of weekly growth in each country\n",
    "\n",
    "def predict(df,i,regressor):\n",
    "    \n",
    "    x=df.iloc[:33+i,17:-1]\n",
    "    y=df.iloc[:33+i,-1]\n",
    "    predictions=regressor.predict(x)\n",
    "    \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({'Actual_rf': y, 'Predicted_rf': predictions})\n",
    "    df.plot(kind='bar',figsize=(10,10))\n",
    "    plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "    plt.title(\"Random forest\",fontsize=16)\n",
    "    plt.xlabel('Date ',fontsize=16)\n",
    "    plt.ylabel('Growth',fontsize=16)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ICom based on the caculated confirmed cases based on the prediction of the weekly growth\n",
    "\n",
    "def ICoM(gdict, tseries, c_r, states):\n",
    "\n",
    "    icom = []\n",
    "    numerator = []\n",
    "    denominator = []\n",
    "    for state in states:\n",
    "        coordinates = np.array([gdict[state][0], gdict[state][1]])\n",
    "        numerator.append(c_r[state] * coordinates)\n",
    "        denominator.append(c_r[state])\n",
    "    numerator = np.sum(np.array(numerator), axis=0)\n",
    "    denominator = sum(denominator)\n",
    "    if denominator == 0:\n",
    "        icom.append(np.array([0, 0]))\n",
    "    else:\n",
    "        icom.append(numerator * (1/denominator))\n",
    "    icom = np.array(icom)\n",
    "    icom = pd.DataFrame({'date': tseries, 'lat': icom[:, 0], 'long': icom[:, 1]})\n",
    "    dist=distFromCenter(icom,gdict,states)\n",
    "    \n",
    "    \n",
    "    return icom , dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create distance from the center based on the ICoM that was created\n",
    "def distFromCenter(centers, gdict, states):\n",
    "\n",
    "    weekly_dist = {}\n",
    "    for index in centers.index:\n",
    "        center = np.array(centers['lat'][index], centers['long'][index])\n",
    "        for key in gdict:\n",
    "            point = np.array(gdict[key])\n",
    "            distance = np.linalg.norm(center - point)\n",
    "            if key in states:\n",
    "                if key not in weekly_dist.keys():\n",
    "                    weekly_dist[key] = [distance]\n",
    "                else:\n",
    "                    weekly_dist[key].append(distance)\n",
    "    return weekly_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read geographic data\n",
    "geo=pd.read_csv(\"geo.csv\")\n",
    "geo.rename(columns = {\"Unnamed: 0\":\"state\",\"0\":\"lat\",\"1\":\"long\"},inplace=True)\n",
    "geo=geo.set_index('state').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dataframe to save the ICOM prediction\n",
    "df_icom=pd.DataFrame()\n",
    "last_val={}\n",
    "df=pd.read_csv(\"France.csv\")\n",
    "t_s=df[\"date\"][32:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a diconery of dataframes where key is the country name\n",
    "\n",
    "state_dict={}\n",
    "predictions={}\n",
    "state_list=['Germany', 'Italy', 'Spain', 'Belgium', 'Switzerland',\n",
    "            'Austria','France','Finland', 'Greece', 'Netherlands']\n",
    "for state in state_list:\n",
    "    df=pd.read_csv(state+\".csv\")\n",
    "    if state not in state_dict.keys():\n",
    "        state_dict[state]=df\n",
    "        state_dict[state]=state_dict[state].fillna(0)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row number for prediction\n",
    "time=32\n",
    "pred=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the original\n",
    "original_data={}\n",
    "for state in state_list:\n",
    "    if state not in original_data.keys():\n",
    "        original_data[state]=state_dict[state].copy()\n",
    "#rename columns\n",
    "for state in state_list:\n",
    "    original_data[state]=original_data[state].rename(columns={\"WeeklyConfirmed\":\"WeeklyConfirmed_actuel\",\n",
    "                                                              \"WeeklyGrowth\":\"WeeklyGrowth_actuel\",\n",
    "                                           \"Weeklydistance\":\"Weeklydistance_actuel\"})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary of trained models and extrect feature imporance for each model\n",
    "\n",
    "train_dict={}\n",
    "feature_df = pd.DataFrame(columns=[\"importance\"])\n",
    "for i,state in enumerate(state_list):\n",
    "    if state not in train_dict.keys():\n",
    "        train_dict[state],data=train(state_dict[state])\n",
    "        feature_df=feature_df.append(data)\n",
    "   \n",
    "        \n",
    "\n",
    "feature_df.to_csv(\"feature importance.csv\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   date        lat      long\n",
      "0     0  45.041943  4.157227\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     1  44.971156  3.928111\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     2  44.899891  3.704734\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     3  44.828648  3.487831\n",
      "\n",
      "\n",
      "   date        lat      long\n",
      "0     4  44.757779  3.278107\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create prediction for the Weekly Growth for every trained model \n",
    "Caculate the Weekly Confiremd Cases based on the predicted Growth for t+1\n",
    "Caculate New ICoM Based on the predicted Confirmed Cases\n",
    "Caculate distance from Center of ICoM for each country\n",
    "\"\"\"\n",
    "for i in range(len(t_s)):\n",
    "\n",
    "   \n",
    "    for state in state_list:\n",
    "        \n",
    "        if state not in predictions.keys():\n",
    "            \n",
    "            predictions[state]=predict(state_dict[state],i,train_dict[state])\n",
    "            \n",
    "            \n",
    "        state_dict[state][\"WeeklyGrowth\"][time+i]=predictions[state][pred+i]\n",
    "        state_dict[state][\"WeeklyConfirmed\"][time+i]=state_dict[state][\"WeeklyGrowth\"][time+i]*state_dict[state][\"WeeklyConfirmed\"][time-1+i]\n",
    "        \n",
    "        if state not in last_val.keys():\n",
    "            last_val[state]= state_dict[state][\"WeeklyConfirmed\"][time+i]\n",
    "            \n",
    "\n",
    "    \n",
    "    icom ,dist =ICoM(geo,i,last_val,state_list)\n",
    "    df_icom=df_icom.append(icom)\n",
    "    for state in state_list:\n",
    "        \n",
    "        state_dict[state][\"Weeklydistance\"][time+i]=dist[state][0]\n",
    "        \n",
    "    last_val.clear()\n",
    "    predictions.clear()\n",
    "    print(icom)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write all the Data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook('predictions_growth.xlsx')\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = load_workbook('predictions_growth.xlsx')\n",
    "writer = pd.ExcelWriter('predictions_growth.xlsx', engine = 'openpyxl')\n",
    "writer.book = book\n",
    "\n",
    "for state in state_list:\n",
    "    \n",
    "\n",
    "    state_dict[state][\"date\"].to_excel(writer, sheet_name=state,index=False)\n",
    "    state_dict[state][\"WeeklyConfirmed\"].to_excel(writer, sheet_name=state,index=False,startcol=1)\n",
    "    state_dict[state][\"WeeklyGrowth\"].to_excel(writer, sheet_name=state,index=False,startcol=2)\n",
    "    state_dict[state][\"Weeklydistance\"].to_excel(writer, sheet_name=state,index=False,startcol=3)\n",
    "    original_data[state][\"WeeklyConfirmed_actuel\"].to_excel(writer, sheet_name=state,startcol=4,index=False)\n",
    "    original_data[state][\"WeeklyGrowth_actuel\"].to_excel(writer, sheet_name=state,startcol=5,index=False)\n",
    "    original_data[state][\"Weeklydistance_actuel\"].to_excel(writer, sheet_name=state,startcol=6,index=False)\n",
    "    writer.save()\n",
    "writer.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = load_workbook('predictions_growth.xlsx')\n",
    "writer = pd.ExcelWriter('predictions_growth.xlsx', engine = 'openpyxl')\n",
    "writer.book = book\n",
    "df_icom.to_excel(writer,sheet_name=\"ICOM\")\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
